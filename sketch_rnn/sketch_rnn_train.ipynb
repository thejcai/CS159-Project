{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Collecting numpy==1.16.2\n",
      "  Using cached https://files.pythonhosted.org/packages/c4/33/8ec8dcdb4ede5d453047bbdbd01916dbaccdb63e98bba60989718f5f0876/numpy-1.16.2-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.16.2\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2019 The Magenta Authors.\n",
    "#\n",
    "\n",
    "\"\"\"SketchRNN training.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "# from magenta.models.sketch_rnn import model as sketch_rnn_model\n",
    "# from magenta.models.sketch_rnn import utils\n",
    "import model as sketch_rnn_model\n",
    "import utils\n",
    "\n",
    "!pip install numpy==1.16.2\n",
    "import numpy as np\n",
    "import requests\n",
    "import six\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'data_dir',\n",
    "    'https://github.com/hardmaru/sketch-rnn-datasets/raw/master/aaron_sheep',\n",
    "    'The directory in which to find the dataset specified in model hparams. '\n",
    "    'If data_dir starts with \"http://\" or \"https://\", the file will be fetched '\n",
    "    'remotely.')\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'log_root', 'log/initial/', # '/tmp/sketch_rnn/models/default',\n",
    "    'Directory to store model checkpoints, tensorboard.')\n",
    "tf.app.flags.DEFINE_boolean(\n",
    "    'resume_training', True,\n",
    "    'Set to true to load previous checkpoint')\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'hparams', '',\n",
    "    'Pass in comma-separated key=value pairs such as '\n",
    "    '\\'save_every=40,decay_rate=0.99\\' '\n",
    "    '(no whitespace) to be read into the HParams object defined in model.py')\n",
    "\n",
    "PRETRAINED_MODELS_URL = ('http://download.magenta.tensorflow.org/models/'\n",
    "                         'sketch_rnn.zip')\n",
    "\n",
    "\n",
    "def reset_graph():\n",
    "    \"\"\"Closes the current default session and resets the graph.\"\"\"\n",
    "    sess = tf.get_default_session()\n",
    "    if sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "\n",
    "def load_env(data_dir, model_dir):\n",
    "    \"\"\"Loads environment for inference mode, used in jupyter notebook.\"\"\"\n",
    "    model_params = sketch_rnn_model.get_default_hparams()\n",
    "    with tf.gfile.Open(os.path.join(model_dir, 'model_config.json'), 'r') as f:\n",
    "        model_params.parse_json(f.read())\n",
    "    return load_dataset(data_dir, model_params, inference_mode=True)\n",
    "\n",
    "\n",
    "def load_model(model_dir):\n",
    "    \"\"\"Loads model for inference mode, used in jupyter notebook.\"\"\"\n",
    "    model_params = sketch_rnn_model.get_default_hparams()\n",
    "    with tf.gfile.Open(os.path.join(model_dir, 'model_config.json'), 'r') as f:\n",
    "        model_params.parse_json(f.read())\n",
    "\n",
    "    model_params.batch_size = 1  # only sample one at a time\n",
    "    eval_model_params = sketch_rnn_model.copy_hparams(model_params)\n",
    "    eval_model_params.use_input_dropout = 0\n",
    "    eval_model_params.use_recurrent_dropout = 0\n",
    "    eval_model_params.use_output_dropout = 0\n",
    "    eval_model_params.is_training = 0\n",
    "    sample_model_params = sketch_rnn_model.copy_hparams(eval_model_params)\n",
    "    sample_model_params.max_seq_len = 1  # sample one point at a time\n",
    "    return [model_params, eval_model_params, sample_model_params]\n",
    "\n",
    "\n",
    "def download_pretrained_models(\n",
    "    models_root_dir='/tmp/sketch_rnn/models',\n",
    "    pretrained_models_url=PRETRAINED_MODELS_URL):\n",
    "    \"\"\"Download pretrained models to a temporary directory.\"\"\"\n",
    "    tf.gfile.MakeDirs(models_root_dir)\n",
    "    zip_path = os.path.join(\n",
    "        models_root_dir, os.path.basename(pretrained_models_url))\n",
    "    if os.path.isfile(zip_path):\n",
    "        tf.logging.info('%s already exists, using cached copy', zip_path)\n",
    "    else:\n",
    "        tf.logging.info('Downloading pretrained models from %s...',\n",
    "                        pretrained_models_url)\n",
    "        urlretrieve(pretrained_models_url, zip_path)\n",
    "        tf.logging.info('Download complete.')\n",
    "    tf.logging.info('Unzipping %s...', zip_path)\n",
    "    with zipfile.ZipFile(zip_path) as models_zip:\n",
    "        models_zip.extractall(models_root_dir)\n",
    "    tf.logging.info('Unzipping complete.')\n",
    "\n",
    "\n",
    "def load_dataset(data_dir, model_params, inference_mode=False):\n",
    "    \"\"\"Loads the .npz file, and splits the set into train/valid/test.\"\"\"\n",
    "\n",
    "    # normalizes the x and y columns using the training set.\n",
    "    # applies same scaling factor to valid and test set.\n",
    "\n",
    "    if isinstance(model_params.data_set, list):\n",
    "        datasets = model_params.data_set\n",
    "    else:\n",
    "        datasets = [model_params.data_set]\n",
    "\n",
    "    train_strokes = None\n",
    "    valid_strokes = None\n",
    "    test_strokes = None\n",
    "\n",
    "    for dataset in datasets:\n",
    "        if data_dir.startswith('http://') or data_dir.startswith('https://'):\n",
    "            data_filepath = '/'.join([data_dir, dataset])\n",
    "            tf.logging.info('Downloading %s', data_filepath)\n",
    "            response = requests.get(data_filepath)\n",
    "            data = np.load(six.BytesIO(response.content), allow_pickle=True, encoding='latin1')\n",
    "        else:\n",
    "            data_filepath = os.path.join(data_dir, dataset)\n",
    "            if six.PY3:\n",
    "                data = np.load(data_filepath, allow_pickle=True, encoding='latin1')\n",
    "            else:\n",
    "                data = np.load(data_filepath, allow_pickle=True)\n",
    "        tf.logging.info('Loaded {}/{}/{} from {}'.format(\n",
    "            len(data['train']), len(data['valid']), len(data['test']),\n",
    "            dataset))\n",
    "        if train_strokes is None:\n",
    "            train_strokes = data['train']\n",
    "            valid_strokes = data['valid']\n",
    "            test_strokes = data['test']\n",
    "        else:\n",
    "            train_strokes = np.concatenate((train_strokes, data['train']))\n",
    "            valid_strokes = np.concatenate((valid_strokes, data['valid']))\n",
    "            test_strokes = np.concatenate((test_strokes, data['test']))\n",
    "\n",
    "    all_strokes = np.concatenate((train_strokes, valid_strokes, test_strokes))\n",
    "    num_points = 0\n",
    "    for stroke in all_strokes:\n",
    "        num_points += len(stroke)\n",
    "    avg_len = num_points / len(all_strokes)\n",
    "    tf.logging.info('Dataset combined: {} ({}/{}/{}), avg len {}'.format(\n",
    "        len(all_strokes), len(train_strokes), len(valid_strokes),\n",
    "        len(test_strokes), int(avg_len)))\n",
    "\n",
    "    # calculate the max strokes we need.\n",
    "    max_seq_len = utils.get_max_len(all_strokes)\n",
    "    # overwrite the hps with this calculation.\n",
    "    model_params.max_seq_len = max_seq_len\n",
    "\n",
    "    tf.logging.info('model_params.max_seq_len %i.', model_params.max_seq_len)\n",
    "\n",
    "    eval_model_params = sketch_rnn_model.copy_hparams(model_params)\n",
    "\n",
    "    eval_model_params.use_input_dropout = 0\n",
    "    eval_model_params.use_recurrent_dropout = 0\n",
    "    eval_model_params.use_output_dropout = 0\n",
    "    eval_model_params.is_training = 1\n",
    "\n",
    "    if inference_mode:\n",
    "        eval_model_params.batch_size = 1\n",
    "        eval_model_params.is_training = 0\n",
    "\n",
    "    sample_model_params = sketch_rnn_model.copy_hparams(eval_model_params)\n",
    "    sample_model_params.batch_size = 1  # only sample one at a time\n",
    "    sample_model_params.max_seq_len = 1  # sample one point at a time\n",
    "\n",
    "    train_set = utils.DataLoader(\n",
    "        train_strokes,\n",
    "        model_params.batch_size,\n",
    "        max_seq_length=model_params.max_seq_len,\n",
    "        random_scale_factor=model_params.random_scale_factor,\n",
    "        augment_stroke_prob=model_params.augment_stroke_prob)\n",
    "\n",
    "    normalizing_scale_factor = train_set.calculate_normalizing_scale_factor()\n",
    "    train_set.normalize(normalizing_scale_factor)\n",
    "\n",
    "    valid_set = utils.DataLoader(\n",
    "        valid_strokes,\n",
    "        eval_model_params.batch_size,\n",
    "        max_seq_length=eval_model_params.max_seq_len,\n",
    "        random_scale_factor=0.0,\n",
    "        augment_stroke_prob=0.0)\n",
    "    valid_set.normalize(normalizing_scale_factor)\n",
    "\n",
    "    test_set = utils.DataLoader(\n",
    "        test_strokes,\n",
    "        eval_model_params.batch_size,\n",
    "        max_seq_length=eval_model_params.max_seq_len,\n",
    "        random_scale_factor=0.0,\n",
    "        augment_stroke_prob=0.0)\n",
    "    test_set.normalize(normalizing_scale_factor)\n",
    "\n",
    "    tf.logging.info('normalizing_scale_factor %4.4f.', normalizing_scale_factor)\n",
    "\n",
    "    result = [\n",
    "        train_set, valid_set, test_set, model_params, eval_model_params,\n",
    "        sample_model_params\n",
    "    ]\n",
    "    return result\n",
    "\n",
    "\n",
    "def evaluate_model(sess, model, data_set):\n",
    "    \"\"\"Returns the average weighted cost, reconstruction cost and KL cost.\"\"\"\n",
    "    total_cost = 0.0\n",
    "    total_r_cost = 0.0\n",
    "    total_kl_cost = 0.0\n",
    "    for batch in range(data_set.num_batches):\n",
    "        unused_orig_x, x, s = data_set.get_batch(batch)\n",
    "        feed = {model.input_data: x, model.sequence_lengths: s}\n",
    "        (cost, r_cost,\n",
    "         kl_cost) = sess.run([model.cost, model.r_cost, model.kl_cost], feed)\n",
    "        total_cost += cost\n",
    "        total_r_cost += r_cost\n",
    "        total_kl_cost += kl_cost\n",
    "\n",
    "    total_cost /= (data_set.num_batches)\n",
    "    total_r_cost /= (data_set.num_batches)\n",
    "    total_kl_cost /= (data_set.num_batches)\n",
    "    return (total_cost, total_r_cost, total_kl_cost)\n",
    "\n",
    "\n",
    "def load_checkpoint(sess, checkpoint_path):\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    ckpt = tf.train.get_checkpoint_state(checkpoint_path)\n",
    "    tf.logging.info('Loading model %s.', ckpt.model_checkpoint_path)\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "\n",
    "def save_model(sess, model_save_path, global_step):\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    checkpoint_path = os.path.join(model_save_path, 'vector')\n",
    "    tf.logging.info('saving model %s.', checkpoint_path)\n",
    "    tf.logging.info('global_step %i.', global_step)\n",
    "    saver.save(sess, checkpoint_path, global_step=global_step)\n",
    "\n",
    "\n",
    "def train(sess, model, eval_model, train_set, valid_set, test_set):\n",
    "    \"\"\"Train a sketch-rnn model.\"\"\"\n",
    "    # Setup summary writer.\n",
    "    summary_writer = tf.summary.FileWriter(FLAGS.log_root)\n",
    "\n",
    "    # Calculate trainable params.\n",
    "    t_vars = tf.trainable_variables()\n",
    "    count_t_vars = 0\n",
    "    for var in t_vars:\n",
    "        num_param = np.prod(var.get_shape().as_list())\n",
    "        count_t_vars += num_param\n",
    "        tf.logging.info('%s %s %i', var.name, str(var.get_shape()), num_param)\n",
    "    tf.logging.info('Total trainable variables %i.', count_t_vars)\n",
    "    model_summ = tf.summary.Summary()\n",
    "    model_summ.value.add(\n",
    "          tag='Num_Trainable_Params', simple_value=float(count_t_vars))\n",
    "    summary_writer.add_summary(model_summ, 0)\n",
    "    summary_writer.flush()\n",
    "\n",
    "    # setup eval stats\n",
    "    best_valid_cost = 100000000.0  # set a large init value\n",
    "    valid_cost = 0.0\n",
    "\n",
    "    # main train loop\n",
    "\n",
    "    hps = model.hps\n",
    "    start = time.time()\n",
    "\n",
    "    for _ in range(hps.num_steps):\n",
    "\n",
    "        step = sess.run(model.global_step)\n",
    "\n",
    "        curr_learning_rate = ((hps.learning_rate - hps.min_learning_rate) *\n",
    "                              (hps.decay_rate)**step + hps.min_learning_rate)\n",
    "        curr_kl_weight = (hps.kl_weight - (hps.kl_weight - hps.kl_weight_start) *\n",
    "                          (hps.kl_decay_rate)**step)\n",
    "\n",
    "        _, x, s = train_set.random_batch()\n",
    "        feed = {\n",
    "            model.input_data: x,\n",
    "            model.sequence_lengths: s,\n",
    "            model.lr: curr_learning_rate,\n",
    "            model.kl_weight: curr_kl_weight\n",
    "        }\n",
    "\n",
    "        (train_cost, r_cost, kl_cost, _, train_step, _) = sess.run([\n",
    "            model.cost, model.r_cost, model.kl_cost, model.final_state,\n",
    "            model.global_step, model.train_op\n",
    "        ], feed)\n",
    "\n",
    "        if step % 20 == 0 and step > 0:\n",
    "\n",
    "            end = time.time()\n",
    "            time_taken = end - start\n",
    "\n",
    "            cost_summ = tf.summary.Summary()\n",
    "            cost_summ.value.add(tag='Train_Cost', simple_value=float(train_cost))\n",
    "            reconstr_summ = tf.summary.Summary()\n",
    "            reconstr_summ.value.add(\n",
    "                tag='Train_Reconstr_Cost', simple_value=float(r_cost))\n",
    "            kl_summ = tf.summary.Summary()\n",
    "            kl_summ.value.add(tag='Train_KL_Cost', simple_value=float(kl_cost))\n",
    "            lr_summ = tf.summary.Summary()\n",
    "            lr_summ.value.add(\n",
    "                tag='Learning_Rate', simple_value=float(curr_learning_rate))\n",
    "            kl_weight_summ = tf.summary.Summary()\n",
    "            kl_weight_summ.value.add(\n",
    "                tag='KL_Weight', simple_value=float(curr_kl_weight))\n",
    "            time_summ = tf.summary.Summary()\n",
    "            time_summ.value.add(\n",
    "                tag='Time_Taken_Train', simple_value=float(time_taken))\n",
    "\n",
    "            output_format = ('step: %d, lr: %.6f, klw: %0.4f, cost: %.4f, '\n",
    "                             'recon: %.4f, kl: %.4f, train_time_taken: %.4f')\n",
    "            output_values = (step, curr_learning_rate, curr_kl_weight, train_cost,\n",
    "                             r_cost, kl_cost, time_taken)\n",
    "            output_log = output_format % output_values\n",
    "\n",
    "            tf.logging.info(output_log)\n",
    "\n",
    "            summary_writer.add_summary(cost_summ, train_step)\n",
    "            summary_writer.add_summary(reconstr_summ, train_step)\n",
    "            summary_writer.add_summary(kl_summ, train_step)\n",
    "            summary_writer.add_summary(lr_summ, train_step)\n",
    "            summary_writer.add_summary(kl_weight_summ, train_step)\n",
    "            summary_writer.add_summary(time_summ, train_step)\n",
    "            summary_writer.flush()\n",
    "            start = time.time()\n",
    "\n",
    "        if step % hps.save_every == 0 and step > 0:\n",
    "\n",
    "            (valid_cost, valid_r_cost, valid_kl_cost) = evaluate_model(\n",
    "                sess, eval_model, valid_set)\n",
    "\n",
    "            end = time.time()\n",
    "            time_taken_valid = end - start\n",
    "            start = time.time()\n",
    "\n",
    "            valid_cost_summ = tf.summary.Summary()\n",
    "            valid_cost_summ.value.add(\n",
    "                tag='Valid_Cost', simple_value=float(valid_cost))\n",
    "            valid_reconstr_summ = tf.summary.Summary()\n",
    "            valid_reconstr_summ.value.add(\n",
    "                tag='Valid_Reconstr_Cost', simple_value=float(valid_r_cost))\n",
    "            valid_kl_summ = tf.summary.Summary()\n",
    "            valid_kl_summ.value.add(\n",
    "                tag='Valid_KL_Cost', simple_value=float(valid_kl_cost))\n",
    "            valid_time_summ = tf.summary.Summary()\n",
    "            valid_time_summ.value.add(\n",
    "                tag='Time_Taken_Valid', simple_value=float(time_taken_valid))\n",
    "\n",
    "            output_format = ('best_valid_cost: %0.4f, valid_cost: %.4f, valid_recon: '\n",
    "                             '%.4f, valid_kl: %.4f, valid_time_taken: %.4f')\n",
    "            output_values = (min(best_valid_cost, valid_cost), valid_cost,\n",
    "                             valid_r_cost, valid_kl_cost, time_taken_valid)\n",
    "            output_log = output_format % output_values\n",
    "\n",
    "            tf.logging.info(output_log)\n",
    "\n",
    "            summary_writer.add_summary(valid_cost_summ, train_step)\n",
    "            summary_writer.add_summary(valid_reconstr_summ, train_step)\n",
    "            summary_writer.add_summary(valid_kl_summ, train_step)\n",
    "            summary_writer.add_summary(valid_time_summ, train_step)\n",
    "            summary_writer.flush()\n",
    "\n",
    "            if valid_cost < best_valid_cost:\n",
    "                best_valid_cost = valid_cost\n",
    "\n",
    "                save_model(sess, FLAGS.log_root, step)\n",
    "\n",
    "                end = time.time()\n",
    "                time_taken_save = end - start\n",
    "                start = time.time()\n",
    "\n",
    "                tf.logging.info('time_taken_save %4.4f.', time_taken_save)\n",
    "\n",
    "                best_valid_cost_summ = tf.summary.Summary()\n",
    "                best_valid_cost_summ.value.add(\n",
    "                    tag='Best_Valid_Cost', simple_value=float(best_valid_cost))\n",
    "\n",
    "                summary_writer.add_summary(best_valid_cost_summ, train_step)\n",
    "                summary_writer.flush()\n",
    "\n",
    "                (eval_cost, eval_r_cost, eval_kl_cost) = evaluate_model(\n",
    "                    sess, eval_model, test_set)\n",
    "\n",
    "                end = time.time()\n",
    "                time_taken_eval = end - start\n",
    "                start = time.time()\n",
    "\n",
    "                eval_cost_summ = tf.summary.Summary()\n",
    "                eval_cost_summ.value.add(tag='Eval_Cost', simple_value=float(eval_cost))\n",
    "                eval_reconstr_summ = tf.summary.Summary()\n",
    "                eval_reconstr_summ.value.add(\n",
    "                    tag='Eval_Reconstr_Cost', simple_value=float(eval_r_cost))\n",
    "                eval_kl_summ = tf.summary.Summary()\n",
    "                eval_kl_summ.value.add(\n",
    "                    tag='Eval_KL_Cost', simple_value=float(eval_kl_cost))\n",
    "                eval_time_summ = tf.summary.Summary()\n",
    "                eval_time_summ.value.add(\n",
    "                    tag='Time_Taken_Eval', simple_value=float(time_taken_eval))\n",
    "\n",
    "                output_format = ('eval_cost: %.4f, eval_recon: %.4f, '\n",
    "                                 'eval_kl: %.4f, eval_time_taken: %.4f')\n",
    "                output_values = (eval_cost, eval_r_cost, eval_kl_cost, time_taken_eval)\n",
    "                output_log = output_format % output_values\n",
    "\n",
    "                tf.logging.info(output_log)\n",
    "\n",
    "                summary_writer.add_summary(eval_cost_summ, train_step)\n",
    "                summary_writer.add_summary(eval_reconstr_summ, train_step)\n",
    "                summary_writer.add_summary(eval_kl_summ, train_step)\n",
    "                summary_writer.add_summary(eval_time_summ, train_step)\n",
    "                summary_writer.flush()\n",
    "\n",
    "\n",
    "def trainer(model_params):\n",
    "    \"\"\"Train a sketch-rnn model.\"\"\"\n",
    "    np.set_printoptions(precision=8, edgeitems=6, linewidth=200, suppress=True)\n",
    "\n",
    "    tf.logging.info('sketch-rnn')\n",
    "    tf.logging.info('Hyperparams:')\n",
    "    for key, val in six.iteritems(model_params.values()):\n",
    "        tf.logging.info('%s = %s', key, str(val))\n",
    "    tf.logging.info('Loading data files.')\n",
    "    datasets = load_dataset(FLAGS.data_dir, model_params)\n",
    "\n",
    "    train_set = datasets[0]\n",
    "    valid_set = datasets[1]\n",
    "    test_set = datasets[2]\n",
    "    model_params = datasets[3]\n",
    "    eval_model_params = datasets[4]\n",
    "\n",
    "    reset_graph()\n",
    "    model = sketch_rnn_model.Model(model_params)\n",
    "    eval_model = sketch_rnn_model.Model(eval_model_params, reuse=True)\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    if FLAGS.resume_training:\n",
    "        load_checkpoint(sess, FLAGS.log_root)\n",
    "\n",
    "    # Write config file to json file.\n",
    "    tf.gfile.MakeDirs(FLAGS.log_root)\n",
    "    with tf.gfile.Open(\n",
    "          os.path.join(FLAGS.log_root, 'model_config.json'), 'w') as f:\n",
    "        json.dump(model_params.values(), f, indent=True)\n",
    "\n",
    "    train(sess, model, eval_model, train_set, valid_set, test_set)\n",
    "\n",
    "\n",
    "def main(unused_argv):\n",
    "    \"\"\"Load model params, save config file and start trainer.\"\"\"\n",
    "    model_params = sketch_rnn_model.get_default_hparams()\n",
    "    if FLAGS.hparams:\n",
    "        model_params.parse(FLAGS.hparams)\n",
    "    trainer(model_params)\n",
    "\n",
    "\n",
    "def console_entry_point():\n",
    "    tf.app.run(main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:sketch-rnn\n",
      "INFO:tensorflow:Hyperparams:\n",
      "INFO:tensorflow:enc_rnn_size = 256\n",
      "INFO:tensorflow:dec_model = layer_norm\n",
      "INFO:tensorflow:data_set = ['aaron_sheep.npz']\n",
      "INFO:tensorflow:num_mixture = 20\n",
      "INFO:tensorflow:is_training = True\n",
      "INFO:tensorflow:batch_size = 100\n",
      "INFO:tensorflow:dec_rnn_size = 512\n",
      "INFO:tensorflow:grad_clip = 1.0\n",
      "INFO:tensorflow:save_every = 500\n",
      "INFO:tensorflow:learning_rate = 0.001\n",
      "INFO:tensorflow:use_recurrent_dropout = True\n",
      "INFO:tensorflow:augment_stroke_prob = 0.1\n",
      "INFO:tensorflow:kl_tolerance = 0.2\n",
      "INFO:tensorflow:recurrent_dropout_prob = 0.9\n",
      "INFO:tensorflow:use_output_dropout = False\n",
      "INFO:tensorflow:z_size = 128\n",
      "INFO:tensorflow:use_input_dropout = False\n",
      "INFO:tensorflow:max_seq_len = 250\n",
      "INFO:tensorflow:output_dropout_prob = 0.9\n",
      "INFO:tensorflow:kl_decay_rate = 0.99995\n",
      "INFO:tensorflow:input_dropout_prob = 0.9\n",
      "INFO:tensorflow:conditional = True\n",
      "INFO:tensorflow:num_steps = 15000\n",
      "INFO:tensorflow:random_scale_factor = 0.15\n",
      "INFO:tensorflow:enc_model = layer_norm\n",
      "INFO:tensorflow:decay_rate = 0.9999\n",
      "INFO:tensorflow:min_learning_rate = 1e-05\n",
      "INFO:tensorflow:kl_weight_start = 0.01\n",
      "INFO:tensorflow:kl_weight = 0.5\n",
      "INFO:tensorflow:Loading data files.\n",
      "INFO:tensorflow:Downloading https://github.com/hardmaru/sketch-rnn-datasets/raw/master/aaron_sheep/aaron_sheep.npz\n",
      "INFO:tensorflow:Loaded 7400/300/300 from aaron_sheep.npz\n",
      "INFO:tensorflow:Dataset combined: 8000 (7400/300/300), avg len 125\n",
      "INFO:tensorflow:model_params.max_seq_len 250.\n",
      "total images <= max_seq_len is 7400\n",
      "total images <= max_seq_len is 300\n",
      "total images <= max_seq_len is 300\n",
      "INFO:tensorflow:normalizing_scale_factor 18.5198.\n",
      "INFO:tensorflow:Model using gpu.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Input dropout mode = False.\n",
      "INFO:tensorflow:Output dropout mode = False.\n",
      "INFO:tensorflow:Recurrent dropout mode = True.\n",
      "WARNING:tensorflow:From /home/jupyter/model.py:89: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/jupyter/rnn.py:288: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/jupyter/model.py:255: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /home/jupyter/model.py:274: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/jupyter/model.py:284: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "INFO:tensorflow:Model using gpu.\n",
      "INFO:tensorflow:Input dropout mode = 0.\n",
      "INFO:tensorflow:Output dropout mode = 0.\n",
      "INFO:tensorflow:Recurrent dropout mode = 0.\n",
      "INFO:tensorflow:Loading model log/initial/vector-15000.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from log/initial/vector-15000\n",
      "INFO:tensorflow:vector_rnn/ENC_RNN/fw/LayerNormLSTMCell/W_xh:0 (5, 1024) 5120\n",
      "INFO:tensorflow:vector_rnn/ENC_RNN/fw/LayerNormLSTMCell/W_hh:0 (256, 1024) 262144\n",
      "INFO:tensorflow:vector_rnn/ENC_RNN/fw/LayerNormLSTMCell/ln_all/ln_gamma:0 (1024,) 1024\n",
      "INFO:tensorflow:vector_rnn/ENC_RNN/fw/LayerNormLSTMCell/ln_all/ln_beta:0 (1024,) 1024\n",
      "INFO:tensorflow:vector_rnn/ENC_RNN/fw/LayerNormLSTMCell/ln_c/ln_gamma:0 (256,) 256\n",
      "INFO:tensorflow:vector_rnn/ENC_RNN/fw/LayerNormLSTMCell/ln_c/ln_beta:0 (256,) 256\n",
      "INFO:tensorflow:vector_rnn/ENC_RNN/bw/LayerNormLSTMCell/W_xh:0 (5, 1024) 5120\n",
      "INFO:tensorflow:vector_rnn/ENC_RNN/bw/LayerNormLSTMCell/W_hh:0 (256, 1024) 262144\n",
      "INFO:tensorflow:vector_rnn/ENC_RNN/bw/LayerNormLSTMCell/ln_all/ln_gamma:0 (1024,) 1024\n",
      "INFO:tensorflow:vector_rnn/ENC_RNN/bw/LayerNormLSTMCell/ln_all/ln_beta:0 (1024,) 1024\n",
      "INFO:tensorflow:vector_rnn/ENC_RNN/bw/LayerNormLSTMCell/ln_c/ln_gamma:0 (256,) 256\n",
      "INFO:tensorflow:vector_rnn/ENC_RNN/bw/LayerNormLSTMCell/ln_c/ln_beta:0 (256,) 256\n",
      "INFO:tensorflow:vector_rnn/ENC_RNN_mu/super_linear_w:0 (512, 128) 65536\n",
      "INFO:tensorflow:vector_rnn/ENC_RNN_mu/super_linear_b:0 (128,) 128\n",
      "INFO:tensorflow:vector_rnn/ENC_RNN_sigma/super_linear_w:0 (512, 128) 65536\n",
      "INFO:tensorflow:vector_rnn/ENC_RNN_sigma/super_linear_b:0 (128,) 128\n",
      "INFO:tensorflow:vector_rnn/linear/super_linear_w:0 (128, 1024) 131072\n",
      "INFO:tensorflow:vector_rnn/linear/super_linear_b:0 (1024,) 1024\n",
      "INFO:tensorflow:vector_rnn/RNN/output_w:0 (512, 123) 62976\n",
      "INFO:tensorflow:vector_rnn/RNN/output_b:0 (123,) 123\n",
      "INFO:tensorflow:vector_rnn/RNN/LayerNormLSTMCell/W_xh:0 (133, 2048) 272384\n",
      "INFO:tensorflow:vector_rnn/RNN/LayerNormLSTMCell/W_hh:0 (512, 2048) 1048576\n",
      "INFO:tensorflow:vector_rnn/RNN/LayerNormLSTMCell/ln_all/ln_gamma:0 (2048,) 2048\n",
      "INFO:tensorflow:vector_rnn/RNN/LayerNormLSTMCell/ln_all/ln_beta:0 (2048,) 2048\n",
      "INFO:tensorflow:vector_rnn/RNN/LayerNormLSTMCell/ln_c/ln_gamma:0 (512,) 512\n",
      "INFO:tensorflow:vector_rnn/RNN/LayerNormLSTMCell/ln_c/ln_beta:0 (512,) 512\n",
      "INFO:tensorflow:Total trainable variables 2192251.\n",
      "INFO:tensorflow:step: 15020, lr: 0.000230, klw: 0.2688, cost: -0.0247, recon: -0.0785, kl: 0.2000, train_time_taken: 123.9055\n",
      "INFO:tensorflow:step: 15040, lr: 0.000230, klw: 0.2690, cost: 0.0016, recon: -0.0522, kl: 0.2000, train_time_taken: 118.2340\n",
      "INFO:tensorflow:step: 15060, lr: 0.000230, klw: 0.2692, cost: -0.0309, recon: -0.0848, kl: 0.2000, train_time_taken: 118.7435\n",
      "INFO:tensorflow:step: 15080, lr: 0.000229, klw: 0.2695, cost: -0.0163, recon: -0.0703, kl: 0.2005, train_time_taken: 120.0031\n",
      "INFO:tensorflow:step: 15100, lr: 0.000229, klw: 0.2697, cost: -0.0165, recon: -0.0722, kl: 0.2066, train_time_taken: 117.7887\n",
      "INFO:tensorflow:step: 15120, lr: 0.000228, klw: 0.2699, cost: -0.0606, recon: -0.1146, kl: 0.2000, train_time_taken: 120.3119\n",
      "INFO:tensorflow:step: 15140, lr: 0.000228, klw: 0.2702, cost: 0.0234, recon: -0.0316, kl: 0.2036, train_time_taken: 119.5750\n",
      "INFO:tensorflow:step: 15160, lr: 0.000227, klw: 0.2704, cost: -0.0452, recon: -0.1009, kl: 0.2059, train_time_taken: 118.4725\n",
      "INFO:tensorflow:step: 15180, lr: 0.000227, klw: 0.2706, cost: 0.0104, recon: -0.0438, kl: 0.2000, train_time_taken: 119.1478\n",
      "INFO:tensorflow:step: 15200, lr: 0.000227, klw: 0.2708, cost: 0.0357, recon: -0.0185, kl: 0.2000, train_time_taken: 118.7074\n",
      "INFO:tensorflow:step: 15220, lr: 0.000226, klw: 0.2711, cost: -0.0584, recon: -0.1131, kl: 0.2018, train_time_taken: 119.1827\n",
      "INFO:tensorflow:step: 15240, lr: 0.000226, klw: 0.2713, cost: 0.0066, recon: -0.0481, kl: 0.2016, train_time_taken: 118.0775\n",
      "INFO:tensorflow:step: 15260, lr: 0.000225, klw: 0.2715, cost: 0.0142, recon: -0.0401, kl: 0.2000, train_time_taken: 118.0509\n",
      "INFO:tensorflow:step: 15280, lr: 0.000225, klw: 0.2718, cost: -0.0719, recon: -0.1272, kl: 0.2036, train_time_taken: 119.4325\n",
      "INFO:tensorflow:step: 15300, lr: 0.000224, klw: 0.2720, cost: -0.0064, recon: -0.0612, kl: 0.2012, train_time_taken: 118.7183\n",
      "INFO:tensorflow:step: 15320, lr: 0.000224, klw: 0.2722, cost: 0.0009, recon: -0.0536, kl: 0.2000, train_time_taken: 118.4450\n",
      "INFO:tensorflow:step: 15340, lr: 0.000223, klw: 0.2724, cost: -0.0276, recon: -0.0821, kl: 0.2000, train_time_taken: 119.9411\n",
      "INFO:tensorflow:step: 15360, lr: 0.000223, klw: 0.2727, cost: -0.0459, recon: -0.1005, kl: 0.2000, train_time_taken: 119.0050\n",
      "INFO:tensorflow:step: 15380, lr: 0.000223, klw: 0.2729, cost: -0.0258, recon: -0.0805, kl: 0.2005, train_time_taken: 119.3254\n",
      "INFO:tensorflow:step: 15400, lr: 0.000222, klw: 0.2731, cost: -0.0360, recon: -0.0906, kl: 0.2000, train_time_taken: 118.0518\n",
      "INFO:tensorflow:step: 15420, lr: 0.000222, klw: 0.2734, cost: 0.0315, recon: -0.0231, kl: 0.2000, train_time_taken: 118.2389\n",
      "INFO:tensorflow:step: 15440, lr: 0.000221, klw: 0.2736, cost: -0.0712, recon: -0.1263, kl: 0.2015, train_time_taken: 118.8299\n",
      "INFO:tensorflow:step: 15460, lr: 0.000221, klw: 0.2738, cost: -0.0660, recon: -0.1209, kl: 0.2005, train_time_taken: 118.0119\n",
      "INFO:tensorflow:step: 15480, lr: 0.000221, klw: 0.2740, cost: 0.0448, recon: -0.0100, kl: 0.2000, train_time_taken: 118.7146\n",
      "INFO:tensorflow:step: 15500, lr: 0.000220, klw: 0.2743, cost: -0.0020, recon: -0.0569, kl: 0.2001, train_time_taken: 119.9097\n",
      "INFO:tensorflow:best_valid_cost: -0.0732, valid_cost: -0.0732, valid_recon: -0.0753, valid_kl: 0.2068, valid_time_taken: 5.6519\n",
      "INFO:tensorflow:saving model log/initial/vector.\n",
      "INFO:tensorflow:global_step 15500.\n",
      "INFO:tensorflow:time_taken_save 0.9400.\n",
      "INFO:tensorflow:eval_cost: -0.0871, eval_recon: -0.0891, eval_kl: 0.2067, eval_time_taken: 5.0632\n",
      "INFO:tensorflow:step: 15520, lr: 0.000220, klw: 0.2745, cost: 0.0011, recon: -0.0538, kl: 0.2001, train_time_taken: 118.9596\n",
      "INFO:tensorflow:step: 15540, lr: 0.000219, klw: 0.2747, cost: -0.0149, recon: -0.0708, kl: 0.2034, train_time_taken: 119.1462\n",
      "INFO:tensorflow:step: 15560, lr: 0.000219, klw: 0.2749, cost: 0.0127, recon: -0.0428, kl: 0.2017, train_time_taken: 118.8521\n",
      "INFO:tensorflow:step: 15580, lr: 0.000218, klw: 0.2752, cost: -0.0112, recon: -0.0662, kl: 0.2000, train_time_taken: 118.6427\n",
      "INFO:tensorflow:step: 15600, lr: 0.000218, klw: 0.2754, cost: 0.0070, recon: -0.0489, kl: 0.2030, train_time_taken: 118.9918\n",
      "INFO:tensorflow:step: 15620, lr: 0.000218, klw: 0.2756, cost: -0.0158, recon: -0.0714, kl: 0.2016, train_time_taken: 118.0594\n",
      "INFO:tensorflow:step: 15640, lr: 0.000217, klw: 0.2758, cost: -0.0520, recon: -0.1071, kl: 0.2000, train_time_taken: 119.9619\n",
      "INFO:tensorflow:step: 15660, lr: 0.000217, klw: 0.2761, cost: -0.0668, recon: -0.1220, kl: 0.2000, train_time_taken: 119.4210\n",
      "INFO:tensorflow:step: 15680, lr: 0.000216, klw: 0.2763, cost: -0.0251, recon: -0.0814, kl: 0.2038, train_time_taken: 118.4364\n",
      "INFO:tensorflow:step: 15700, lr: 0.000216, klw: 0.2765, cost: -0.0229, recon: -0.0782, kl: 0.2000, train_time_taken: 118.6697\n",
      "INFO:tensorflow:step: 15720, lr: 0.000216, klw: 0.2767, cost: -0.0904, recon: -0.1461, kl: 0.2013, train_time_taken: 119.0364\n",
      "INFO:tensorflow:step: 15740, lr: 0.000215, klw: 0.2770, cost: -0.0088, recon: -0.0641, kl: 0.2000, train_time_taken: 118.2387\n",
      "INFO:tensorflow:step: 15760, lr: 0.000215, klw: 0.2772, cost: 0.0135, recon: -0.0419, kl: 0.2000, train_time_taken: 117.9798\n",
      "INFO:tensorflow:step: 15780, lr: 0.000214, klw: 0.2774, cost: -0.0698, recon: -0.1258, kl: 0.2020, train_time_taken: 117.1206\n",
      "INFO:tensorflow:step: 15800, lr: 0.000214, klw: 0.2776, cost: -0.0518, recon: -0.1077, kl: 0.2015, train_time_taken: 120.0647\n",
      "INFO:tensorflow:step: 15820, lr: 0.000213, klw: 0.2778, cost: -0.0020, recon: -0.0576, kl: 0.2000, train_time_taken: 117.4173\n",
      "INFO:tensorflow:step: 15840, lr: 0.000213, klw: 0.2781, cost: -0.0315, recon: -0.0874, kl: 0.2010, train_time_taken: 118.2031\n",
      "INFO:tensorflow:step: 15860, lr: 0.000213, klw: 0.2783, cost: 0.0318, recon: -0.0239, kl: 0.2001, train_time_taken: 118.1653\n",
      "INFO:tensorflow:step: 15880, lr: 0.000212, klw: 0.2785, cost: -0.0758, recon: -0.1315, kl: 0.2000, train_time_taken: 118.9101\n",
      "INFO:tensorflow:step: 15900, lr: 0.000212, klw: 0.2787, cost: 0.0185, recon: -0.0372, kl: 0.2000, train_time_taken: 118.4037\n",
      "INFO:tensorflow:step: 15920, lr: 0.000211, klw: 0.2790, cost: -0.0395, recon: -0.0953, kl: 0.2000, train_time_taken: 118.8880\n",
      "INFO:tensorflow:step: 15940, lr: 0.000211, klw: 0.2792, cost: -0.0248, recon: -0.0806, kl: 0.2000, train_time_taken: 117.8658\n",
      "INFO:tensorflow:step: 15960, lr: 0.000211, klw: 0.2794, cost: -0.0686, recon: -0.1251, kl: 0.2024, train_time_taken: 119.9467\n",
      "INFO:tensorflow:step: 15980, lr: 0.000210, klw: 0.2796, cost: 0.0536, recon: -0.0023, kl: 0.2000, train_time_taken: 118.9592\n",
      "INFO:tensorflow:step: 16000, lr: 0.000210, klw: 0.2798, cost: 0.0446, recon: -0.0114, kl: 0.2000, train_time_taken: 118.7362\n",
      "INFO:tensorflow:best_valid_cost: -0.0847, valid_cost: -0.0847, valid_recon: -0.0868, valid_kl: 0.2066, valid_time_taken: 4.7792\n",
      "INFO:tensorflow:saving model log/initial/vector.\n",
      "INFO:tensorflow:global_step 16000.\n",
      "INFO:tensorflow:time_taken_save 0.6352.\n",
      "INFO:tensorflow:eval_cost: -0.1055, eval_recon: -0.1076, eval_kl: 0.2066, eval_time_taken: 5.1447\n",
      "INFO:tensorflow:step: 16020, lr: 0.000209, klw: 0.2801, cost: -0.0693, recon: -0.1260, kl: 0.2025, train_time_taken: 119.2079\n",
      "INFO:tensorflow:step: 16040, lr: 0.000209, klw: 0.2803, cost: -0.0155, recon: -0.0715, kl: 0.2000, train_time_taken: 117.6725\n",
      "INFO:tensorflow:step: 16060, lr: 0.000209, klw: 0.2805, cost: -0.0297, recon: -0.0858, kl: 0.2000, train_time_taken: 118.6065\n",
      "INFO:tensorflow:step: 16080, lr: 0.000208, klw: 0.2807, cost: -0.1114, recon: -0.1686, kl: 0.2039, train_time_taken: 119.0298\n",
      "INFO:tensorflow:step: 16100, lr: 0.000208, klw: 0.2809, cost: -0.0166, recon: -0.0739, kl: 0.2040, train_time_taken: 118.4566\n",
      "INFO:tensorflow:step: 16120, lr: 0.000207, klw: 0.2812, cost: -0.0238, recon: -0.0801, kl: 0.2003, train_time_taken: 118.2745\n",
      "INFO:tensorflow:step: 16140, lr: 0.000207, klw: 0.2814, cost: -0.0285, recon: -0.0848, kl: 0.2000, train_time_taken: 119.4531\n",
      "INFO:tensorflow:step: 16160, lr: 0.000207, klw: 0.2816, cost: -0.0349, recon: -0.0912, kl: 0.2000, train_time_taken: 118.9045\n",
      "INFO:tensorflow:step: 16180, lr: 0.000206, klw: 0.2818, cost: 0.0477, recon: -0.0086, kl: 0.2000, train_time_taken: 118.8089\n",
      "INFO:tensorflow:step: 16200, lr: 0.000206, klw: 0.2820, cost: -0.0622, recon: -0.1197, kl: 0.2040, train_time_taken: 118.6081\n",
      "INFO:tensorflow:step: 16220, lr: 0.000206, klw: 0.2822, cost: -0.0088, recon: -0.0666, kl: 0.2048, train_time_taken: 118.3202\n",
      "INFO:tensorflow:step: 16240, lr: 0.000205, klw: 0.2825, cost: -0.1185, recon: -0.1753, kl: 0.2011, train_time_taken: 117.8069\n",
      "INFO:tensorflow:step: 16260, lr: 0.000205, klw: 0.2827, cost: -0.0388, recon: -0.0954, kl: 0.2000, train_time_taken: 118.3540\n",
      "INFO:tensorflow:step: 16280, lr: 0.000204, klw: 0.2829, cost: -0.0093, recon: -0.0677, kl: 0.2064, train_time_taken: 119.3616\n",
      "INFO:tensorflow:step: 16300, lr: 0.000204, klw: 0.2831, cost: -0.0937, recon: -0.1504, kl: 0.2000, train_time_taken: 118.8604\n",
      "INFO:tensorflow:step: 16320, lr: 0.000204, klw: 0.2833, cost: 0.0239, recon: -0.0328, kl: 0.2000, train_time_taken: 117.6849\n",
      "INFO:tensorflow:step: 16340, lr: 0.000203, klw: 0.2835, cost: -0.0315, recon: -0.0889, kl: 0.2026, train_time_taken: 118.7253\n",
      "INFO:tensorflow:step: 16360, lr: 0.000203, klw: 0.2838, cost: 0.0087, recon: -0.0487, kl: 0.2023, train_time_taken: 118.9884\n",
      "INFO:tensorflow:step: 16380, lr: 0.000202, klw: 0.2840, cost: -0.0623, recon: -0.1200, kl: 0.2032, train_time_taken: 118.5691\n",
      "INFO:tensorflow:step: 16400, lr: 0.000202, klw: 0.2842, cost: -0.0542, recon: -0.1114, kl: 0.2010, train_time_taken: 118.8554\n",
      "INFO:tensorflow:step: 16420, lr: 0.000202, klw: 0.2844, cost: -0.0035, recon: -0.0607, kl: 0.2011, train_time_taken: 118.9867\n",
      "INFO:tensorflow:step: 16440, lr: 0.000201, klw: 0.2846, cost: -0.0163, recon: -0.0737, kl: 0.2016, train_time_taken: 119.2314\n",
      "INFO:tensorflow:step: 16460, lr: 0.000201, klw: 0.2848, cost: -0.0567, recon: -0.1151, kl: 0.2050, train_time_taken: 118.6255\n",
      "INFO:tensorflow:step: 16480, lr: 0.000200, klw: 0.2851, cost: -0.0885, recon: -0.1475, kl: 0.2070, train_time_taken: 118.6591\n",
      "INFO:tensorflow:step: 16500, lr: 0.000200, klw: 0.2853, cost: 0.0407, recon: -0.0164, kl: 0.2000, train_time_taken: 119.9085\n",
      "INFO:tensorflow:best_valid_cost: -0.0879, valid_cost: -0.0879, valid_recon: -0.0900, valid_kl: 0.2054, valid_time_taken: 4.7037\n",
      "INFO:tensorflow:saving model log/initial/vector.\n",
      "INFO:tensorflow:global_step 16500.\n",
      "INFO:tensorflow:time_taken_save 0.6666.\n",
      "INFO:tensorflow:eval_cost: -0.1076, eval_recon: -0.1096, eval_kl: 0.2056, eval_time_taken: 4.8256\n",
      "INFO:tensorflow:step: 16520, lr: 0.000200, klw: 0.2855, cost: -0.0485, recon: -0.1056, kl: 0.2000, train_time_taken: 118.3291\n",
      "INFO:tensorflow:step: 16540, lr: 0.000199, klw: 0.2857, cost: -0.0494, recon: -0.1074, kl: 0.2030, train_time_taken: 119.6611\n",
      "INFO:tensorflow:step: 16560, lr: 0.000199, klw: 0.2859, cost: -0.0628, recon: -0.1206, kl: 0.2022, train_time_taken: 117.9347\n",
      "INFO:tensorflow:step: 16580, lr: 0.000199, klw: 0.2861, cost: 0.0100, recon: -0.0476, kl: 0.2011, train_time_taken: 119.4164\n",
      "INFO:tensorflow:step: 16600, lr: 0.000198, klw: 0.2863, cost: 0.0050, recon: -0.0526, kl: 0.2012, train_time_taken: 118.6500\n",
      "INFO:tensorflow:step: 16620, lr: 0.000198, klw: 0.2866, cost: -0.0468, recon: -0.1043, kl: 0.2006, train_time_taken: 118.7193\n",
      "INFO:tensorflow:step: 16640, lr: 0.000197, klw: 0.2868, cost: 0.0053, recon: -0.0529, kl: 0.2031, train_time_taken: 120.0014\n",
      "INFO:tensorflow:step: 16660, lr: 0.000197, klw: 0.2870, cost: -0.0580, recon: -0.1154, kl: 0.2000, train_time_taken: 118.9514\n",
      "INFO:tensorflow:step: 16680, lr: 0.000197, klw: 0.2872, cost: -0.0153, recon: -0.0736, kl: 0.2029, train_time_taken: 118.3912\n",
      "INFO:tensorflow:step: 16700, lr: 0.000196, klw: 0.2874, cost: -0.0848, recon: -0.1431, kl: 0.2026, train_time_taken: 118.5947\n",
      "INFO:tensorflow:step: 16720, lr: 0.000196, klw: 0.2876, cost: -0.0524, recon: -0.1105, kl: 0.2021, train_time_taken: 118.3569\n",
      "INFO:tensorflow:step: 16740, lr: 0.000196, klw: 0.2878, cost: -0.0453, recon: -0.1029, kl: 0.2000, train_time_taken: 118.2547\n",
      "INFO:tensorflow:step: 16760, lr: 0.000195, klw: 0.2880, cost: -0.0008, recon: -0.0587, kl: 0.2010, train_time_taken: 119.2149\n",
      "INFO:tensorflow:step: 16780, lr: 0.000195, klw: 0.2883, cost: -0.0541, recon: -0.1124, kl: 0.2023, train_time_taken: 118.7425\n",
      "INFO:tensorflow:step: 16800, lr: 0.000194, klw: 0.2885, cost: 0.0034, recon: -0.0543, kl: 0.2000, train_time_taken: 121.0806\n",
      "INFO:tensorflow:step: 16820, lr: 0.000194, klw: 0.2887, cost: -0.0459, recon: -0.1036, kl: 0.2000, train_time_taken: 120.0119\n",
      "INFO:tensorflow:step: 16840, lr: 0.000194, klw: 0.2889, cost: -0.0379, recon: -0.0962, kl: 0.2019, train_time_taken: 119.0529\n",
      "INFO:tensorflow:step: 16860, lr: 0.000193, klw: 0.2891, cost: 0.0721, recon: 0.0131, kl: 0.2040, train_time_taken: 119.0767\n",
      "INFO:tensorflow:step: 16880, lr: 0.000193, klw: 0.2893, cost: -0.0712, recon: -0.1294, kl: 0.2011, train_time_taken: 118.7149\n",
      "INFO:tensorflow:step: 16900, lr: 0.000193, klw: 0.2895, cost: 0.0305, recon: -0.0275, kl: 0.2000, train_time_taken: 118.3668\n",
      "INFO:tensorflow:step: 16920, lr: 0.000192, klw: 0.2897, cost: -0.0367, recon: -0.0957, kl: 0.2037, train_time_taken: 118.6960\n",
      "INFO:tensorflow:step: 16940, lr: 0.000192, klw: 0.2899, cost: -0.0638, recon: -0.1225, kl: 0.2024, train_time_taken: 119.7027\n",
      "INFO:tensorflow:step: 16960, lr: 0.000192, klw: 0.2902, cost: -0.0635, recon: -0.1220, kl: 0.2015, train_time_taken: 117.5999\n",
      "INFO:tensorflow:step: 16980, lr: 0.000191, klw: 0.2904, cost: -0.0230, recon: -0.0829, kl: 0.2063, train_time_taken: 119.3539\n",
      "INFO:tensorflow:step: 17000, lr: 0.000191, klw: 0.2906, cost: -0.0626, recon: -0.1214, kl: 0.2025, train_time_taken: 119.6136\n",
      "INFO:tensorflow:best_valid_cost: -0.1017, valid_cost: -0.1017, valid_recon: -0.1038, valid_kl: 0.2079, valid_time_taken: 4.9893\n",
      "INFO:tensorflow:saving model log/initial/vector.\n",
      "INFO:tensorflow:global_step 17000.\n",
      "INFO:tensorflow:time_taken_save 0.6010.\n",
      "INFO:tensorflow:eval_cost: -0.1184, eval_recon: -0.1204, eval_kl: 0.2075, eval_time_taken: 4.7865\n",
      "INFO:tensorflow:step: 17020, lr: 0.000190, klw: 0.2908, cost: -0.0107, recon: -0.0694, kl: 0.2019, train_time_taken: 117.7230\n",
      "INFO:tensorflow:step: 17040, lr: 0.000190, klw: 0.2910, cost: -0.0210, recon: -0.0799, kl: 0.2024, train_time_taken: 118.0930\n",
      "INFO:tensorflow:step: 17060, lr: 0.000190, klw: 0.2912, cost: -0.0337, recon: -0.0919, kl: 0.2000, train_time_taken: 119.1007\n",
      "INFO:tensorflow:step: 17080, lr: 0.000189, klw: 0.2914, cost: -0.0049, recon: -0.0632, kl: 0.2000, train_time_taken: 118.8491\n",
      "INFO:tensorflow:step: 17100, lr: 0.000189, klw: 0.2916, cost: -0.0371, recon: -0.0955, kl: 0.2000, train_time_taken: 119.3283\n",
      "INFO:tensorflow:step: 17120, lr: 0.000189, klw: 0.2918, cost: -0.0464, recon: -0.1047, kl: 0.2000, train_time_taken: 118.9789\n",
      "INFO:tensorflow:step: 17140, lr: 0.000188, klw: 0.2920, cost: -0.0344, recon: -0.0928, kl: 0.2000, train_time_taken: 118.7054\n",
      "INFO:tensorflow:step: 17160, lr: 0.000188, klw: 0.2922, cost: -0.0375, recon: -0.0966, kl: 0.2020, train_time_taken: 118.6323\n",
      "INFO:tensorflow:step: 17180, lr: 0.000188, klw: 0.2924, cost: -0.0263, recon: -0.0848, kl: 0.2000, train_time_taken: 119.1314\n",
      "INFO:tensorflow:step: 17200, lr: 0.000187, klw: 0.2927, cost: -0.0375, recon: -0.0976, kl: 0.2053, train_time_taken: 119.7493\n",
      "INFO:tensorflow:step: 17220, lr: 0.000187, klw: 0.2929, cost: -0.0747, recon: -0.1340, kl: 0.2022, train_time_taken: 118.6179\n",
      "INFO:tensorflow:step: 17240, lr: 0.000187, klw: 0.2931, cost: 0.0379, recon: -0.0207, kl: 0.2000, train_time_taken: 118.1605\n",
      "INFO:tensorflow:step: 17260, lr: 0.000186, klw: 0.2933, cost: 0.0147, recon: -0.0439, kl: 0.2000, train_time_taken: 119.3929\n",
      "INFO:tensorflow:step: 17280, lr: 0.000186, klw: 0.2935, cost: -0.0045, recon: -0.0632, kl: 0.2000, train_time_taken: 118.4422\n",
      "INFO:tensorflow:step: 17300, lr: 0.000185, klw: 0.2937, cost: -0.0355, recon: -0.0947, kl: 0.2013, train_time_taken: 118.3126\n",
      "INFO:tensorflow:step: 17320, lr: 0.000185, klw: 0.2939, cost: 0.0029, recon: -0.0570, kl: 0.2036, train_time_taken: 119.4255\n",
      "INFO:tensorflow:step: 17340, lr: 0.000185, klw: 0.2941, cost: 0.0294, recon: -0.0300, kl: 0.2019, train_time_taken: 118.8960\n",
      "INFO:tensorflow:step: 17360, lr: 0.000184, klw: 0.2943, cost: -0.1063, recon: -0.1651, kl: 0.2000, train_time_taken: 119.0097\n",
      "INFO:tensorflow:step: 17380, lr: 0.000184, klw: 0.2945, cost: -0.0894, recon: -0.1484, kl: 0.2004, train_time_taken: 118.3544\n",
      "INFO:tensorflow:step: 17400, lr: 0.000184, klw: 0.2947, cost: -0.0308, recon: -0.0907, kl: 0.2035, train_time_taken: 118.1153\n",
      "INFO:tensorflow:step: 17420, lr: 0.000183, klw: 0.2949, cost: -0.0741, recon: -0.1343, kl: 0.2042, train_time_taken: 118.7776\n",
      "INFO:tensorflow:step: 17440, lr: 0.000183, klw: 0.2951, cost: -0.0852, recon: -0.1442, kl: 0.2000, train_time_taken: 117.7110\n",
      "INFO:tensorflow:step: 17460, lr: 0.000183, klw: 0.2953, cost: -0.0108, recon: -0.0699, kl: 0.2000, train_time_taken: 117.5837\n",
      "INFO:tensorflow:step: 17480, lr: 0.000182, klw: 0.2955, cost: 0.0238, recon: -0.0353, kl: 0.2000, train_time_taken: 118.6704\n",
      "INFO:tensorflow:step: 17500, lr: 0.000182, klw: 0.2957, cost: -0.0964, recon: -0.1557, kl: 0.2003, train_time_taken: 118.7504\n",
      "INFO:tensorflow:best_valid_cost: -0.1070, valid_cost: -0.1070, valid_recon: -0.1091, valid_kl: 0.2053, valid_time_taken: 4.8626\n",
      "INFO:tensorflow:saving model log/initial/vector.\n",
      "INFO:tensorflow:global_step 17500.\n",
      "INFO:tensorflow:time_taken_save 0.6639.\n",
      "INFO:tensorflow:eval_cost: -0.1198, eval_recon: -0.1219, eval_kl: 0.2054, eval_time_taken: 4.8706\n",
      "INFO:tensorflow:step: 17520, lr: 0.000182, klw: 0.2959, cost: -0.0074, recon: -0.0666, kl: 0.2000, train_time_taken: 119.1059\n",
      "INFO:tensorflow:step: 17540, lr: 0.000181, klw: 0.2962, cost: -0.0593, recon: -0.1193, kl: 0.2026, train_time_taken: 119.1431\n",
      "INFO:tensorflow:step: 17560, lr: 0.000181, klw: 0.2964, cost: -0.1079, recon: -0.1686, kl: 0.2050, train_time_taken: 118.3195\n",
      "INFO:tensorflow:step: 17580, lr: 0.000181, klw: 0.2966, cost: -0.0588, recon: -0.1181, kl: 0.2000, train_time_taken: 119.7239\n",
      "INFO:tensorflow:step: 17600, lr: 0.000180, klw: 0.2968, cost: -0.0642, recon: -0.1236, kl: 0.2001, train_time_taken: 119.7765\n",
      "INFO:tensorflow:step: 17620, lr: 0.000180, klw: 0.2970, cost: -0.0540, recon: -0.1134, kl: 0.2000, train_time_taken: 119.3312\n",
      "INFO:tensorflow:step: 17640, lr: 0.000180, klw: 0.2972, cost: -0.0846, recon: -0.1448, kl: 0.2025, train_time_taken: 118.4474\n",
      "INFO:tensorflow:step: 17660, lr: 0.000179, klw: 0.2974, cost: -0.0306, recon: -0.0902, kl: 0.2004, train_time_taken: 118.2980\n",
      "INFO:tensorflow:step: 17680, lr: 0.000179, klw: 0.2976, cost: -0.0707, recon: -0.1302, kl: 0.2000, train_time_taken: 118.4358\n",
      "INFO:tensorflow:step: 17700, lr: 0.000179, klw: 0.2978, cost: -0.0583, recon: -0.1194, kl: 0.2051, train_time_taken: 118.3146\n",
      "INFO:tensorflow:step: 17720, lr: 0.000178, klw: 0.2980, cost: -0.0574, recon: -0.1170, kl: 0.2000, train_time_taken: 119.4808\n",
      "INFO:tensorflow:step: 17740, lr: 0.000178, klw: 0.2982, cost: -0.0378, recon: -0.0977, kl: 0.2011, train_time_taken: 118.1160\n",
      "INFO:tensorflow:step: 17760, lr: 0.000178, klw: 0.2984, cost: -0.0576, recon: -0.1173, kl: 0.2000, train_time_taken: 119.1007\n",
      "INFO:tensorflow:step: 17780, lr: 0.000177, klw: 0.2986, cost: -0.0912, recon: -0.1510, kl: 0.2000, train_time_taken: 119.8865\n",
      "INFO:tensorflow:step: 17800, lr: 0.000177, klw: 0.2988, cost: -0.0365, recon: -0.0977, kl: 0.2047, train_time_taken: 116.7997\n",
      "INFO:tensorflow:step: 17820, lr: 0.000177, klw: 0.2990, cost: -0.0823, recon: -0.1421, kl: 0.2000, train_time_taken: 117.9992\n",
      "INFO:tensorflow:step: 17840, lr: 0.000176, klw: 0.2992, cost: -0.0226, recon: -0.0825, kl: 0.2000, train_time_taken: 119.6014\n",
      "INFO:tensorflow:step: 17860, lr: 0.000176, klw: 0.2994, cost: -0.0213, recon: -0.0812, kl: 0.2000, train_time_taken: 118.4977\n",
      "INFO:tensorflow:step: 17880, lr: 0.000176, klw: 0.2996, cost: -0.0579, recon: -0.1181, kl: 0.2009, train_time_taken: 119.1574\n",
      "INFO:tensorflow:step: 17900, lr: 0.000175, klw: 0.2998, cost: -0.0129, recon: -0.0731, kl: 0.2009, train_time_taken: 118.0568\n",
      "INFO:tensorflow:step: 17920, lr: 0.000175, klw: 0.3000, cost: -0.0878, recon: -0.1479, kl: 0.2003, train_time_taken: 117.4682\n",
      "INFO:tensorflow:step: 17940, lr: 0.000175, klw: 0.3002, cost: -0.0402, recon: -0.1004, kl: 0.2005, train_time_taken: 119.2831\n",
      "INFO:tensorflow:step: 17960, lr: 0.000174, klw: 0.3004, cost: -0.0345, recon: -0.0953, kl: 0.2022, train_time_taken: 119.2772\n",
      "INFO:tensorflow:step: 17980, lr: 0.000174, klw: 0.3006, cost: -0.0314, recon: -0.0915, kl: 0.2000, train_time_taken: 118.8863\n",
      "INFO:tensorflow:step: 18000, lr: 0.000174, klw: 0.3008, cost: -0.0518, recon: -0.1119, kl: 0.2000, train_time_taken: 118.9271\n",
      "INFO:tensorflow:best_valid_cost: -0.1070, valid_cost: -0.0999, valid_recon: -0.1019, valid_kl: 0.2051, valid_time_taken: 5.0445\n",
      "INFO:tensorflow:step: 18020, lr: 0.000173, klw: 0.3010, cost: -0.0561, recon: -0.1165, kl: 0.2006, train_time_taken: 118.1946\n",
      "INFO:tensorflow:step: 18040, lr: 0.000173, klw: 0.3012, cost: -0.0890, recon: -0.1499, kl: 0.2023, train_time_taken: 119.2109\n",
      "INFO:tensorflow:step: 18060, lr: 0.000173, klw: 0.3014, cost: -0.0251, recon: -0.0853, kl: 0.2000, train_time_taken: 118.5877\n",
      "INFO:tensorflow:step: 18080, lr: 0.000172, klw: 0.3016, cost: -0.0437, recon: -0.1040, kl: 0.2000, train_time_taken: 118.3015\n",
      "INFO:tensorflow:step: 18100, lr: 0.000172, klw: 0.3018, cost: -0.0673, recon: -0.1277, kl: 0.2004, train_time_taken: 118.3331\n",
      "INFO:tensorflow:step: 18120, lr: 0.000172, klw: 0.3020, cost: -0.1138, recon: -0.1742, kl: 0.2000, train_time_taken: 118.2100\n",
      "INFO:tensorflow:step: 18140, lr: 0.000171, klw: 0.3022, cost: -0.0582, recon: -0.1187, kl: 0.2000, train_time_taken: 119.7476\n",
      "INFO:tensorflow:step: 18160, lr: 0.000171, klw: 0.3024, cost: -0.0539, recon: -0.1144, kl: 0.2000, train_time_taken: 117.6600\n",
      "INFO:tensorflow:step: 18180, lr: 0.000171, klw: 0.3026, cost: -0.0346, recon: -0.0959, kl: 0.2026, train_time_taken: 117.8115\n",
      "INFO:tensorflow:step: 18200, lr: 0.000170, klw: 0.3028, cost: -0.0660, recon: -0.1265, kl: 0.2000, train_time_taken: 120.1741\n",
      "INFO:tensorflow:step: 18220, lr: 0.000170, klw: 0.3030, cost: -0.0317, recon: -0.0927, kl: 0.2014, train_time_taken: 118.0052\n",
      "INFO:tensorflow:step: 18240, lr: 0.000170, klw: 0.3032, cost: -0.0678, recon: -0.1285, kl: 0.2002, train_time_taken: 119.4245\n",
      "INFO:tensorflow:step: 18260, lr: 0.000169, klw: 0.3034, cost: -0.0882, recon: -0.1489, kl: 0.2000, train_time_taken: 118.7554\n",
      "INFO:tensorflow:step: 18280, lr: 0.000169, klw: 0.3036, cost: -0.0441, recon: -0.1057, kl: 0.2029, train_time_taken: 118.4928\n",
      "INFO:tensorflow:step: 18300, lr: 0.000169, klw: 0.3038, cost: -0.0808, recon: -0.1420, kl: 0.2015, train_time_taken: 118.5230\n",
      "INFO:tensorflow:step: 18320, lr: 0.000168, klw: 0.3039, cost: 0.0247, recon: -0.0361, kl: 0.2000, train_time_taken: 119.3971\n",
      "INFO:tensorflow:step: 18340, lr: 0.000168, klw: 0.3041, cost: -0.0348, recon: -0.0965, kl: 0.2028, train_time_taken: 118.7117\n",
      "INFO:tensorflow:step: 18360, lr: 0.000168, klw: 0.3043, cost: -0.0262, recon: -0.0871, kl: 0.2000, train_time_taken: 119.3024\n",
      "INFO:tensorflow:step: 18380, lr: 0.000168, klw: 0.3045, cost: 0.0187, recon: -0.0422, kl: 0.2000, train_time_taken: 118.5836\n",
      "INFO:tensorflow:step: 18400, lr: 0.000167, klw: 0.3047, cost: -0.0349, recon: -0.0972, kl: 0.2043, train_time_taken: 118.8127\n",
      "INFO:tensorflow:step: 18420, lr: 0.000167, klw: 0.3049, cost: -0.1093, recon: -0.1707, kl: 0.2012, train_time_taken: 119.0972\n",
      "INFO:tensorflow:step: 18440, lr: 0.000167, klw: 0.3051, cost: -0.0570, recon: -0.1188, kl: 0.2025, train_time_taken: 118.4132\n",
      "INFO:tensorflow:step: 18460, lr: 0.000166, klw: 0.3053, cost: -0.0848, recon: -0.1474, kl: 0.2049, train_time_taken: 119.4013\n",
      "INFO:tensorflow:step: 18480, lr: 0.000166, klw: 0.3055, cost: -0.0732, recon: -0.1343, kl: 0.2000, train_time_taken: 118.6119\n",
      "INFO:tensorflow:step: 18500, lr: 0.000166, klw: 0.3057, cost: -0.0387, recon: -0.1003, kl: 0.2015, train_time_taken: 119.1541\n",
      "INFO:tensorflow:best_valid_cost: -0.1123, valid_cost: -0.1123, valid_recon: -0.1144, valid_kl: 0.2070, valid_time_taken: 5.0458\n",
      "INFO:tensorflow:saving model log/initial/vector.\n",
      "INFO:tensorflow:global_step 18500.\n",
      "INFO:tensorflow:time_taken_save 0.6246.\n",
      "INFO:tensorflow:eval_cost: -0.1266, eval_recon: -0.1287, eval_kl: 0.2066, eval_time_taken: 4.7972\n",
      "INFO:tensorflow:step: 18520, lr: 0.000165, klw: 0.3059, cost: -0.1354, recon: -0.1972, kl: 0.2020, train_time_taken: 118.4542\n",
      "INFO:tensorflow:step: 18540, lr: 0.000165, klw: 0.3061, cost: -0.0361, recon: -0.0980, kl: 0.2021, train_time_taken: 117.5305\n",
      "INFO:tensorflow:step: 18560, lr: 0.000165, klw: 0.3063, cost: -0.0236, recon: -0.0848, kl: 0.2000, train_time_taken: 118.6231\n",
      "INFO:tensorflow:step: 18580, lr: 0.000164, klw: 0.3065, cost: -0.0737, recon: -0.1350, kl: 0.2000, train_time_taken: 117.7068\n",
      "INFO:tensorflow:step: 18600, lr: 0.000164, klw: 0.3067, cost: -0.0368, recon: -0.0981, kl: 0.2000, train_time_taken: 117.9402\n",
      "INFO:tensorflow:step: 18620, lr: 0.000164, klw: 0.3069, cost: -0.0775, recon: -0.1389, kl: 0.2000, train_time_taken: 118.8380\n",
      "INFO:tensorflow:step: 18640, lr: 0.000163, klw: 0.3071, cost: -0.1184, recon: -0.1799, kl: 0.2004, train_time_taken: 117.1162\n",
      "INFO:tensorflow:step: 18660, lr: 0.000163, klw: 0.3073, cost: -0.0803, recon: -0.1420, kl: 0.2009, train_time_taken: 117.7314\n",
      "INFO:tensorflow:step: 18680, lr: 0.000163, klw: 0.3074, cost: -0.0925, recon: -0.1540, kl: 0.2001, train_time_taken: 117.1885\n"
     ]
    }
   ],
   "source": [
    "console_entry_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
